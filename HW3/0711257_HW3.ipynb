{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3: Decision Tree, AdaBoost and Random Forest\n",
    "In hw3, you need to implement decision tree, adaboost and random forest by using only numpy, then train your implemented model by the provided dataset. TA will use the on-hold test label to evaluate your model performance.\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling `sklearn.tree.DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 5 of hw3 slides](https://docs.google.com/presentation/d/1kIe_-YZdemRMmr_3xDy-l0OS2EcLgDH7Uan14tlU5KE/edit#slide=id.gd542a5ff75_0_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste your implementations right here to check your result\n",
    "# (Of course you can add your classes not written here)\n",
    "import numpy as np\n",
    "def gini(sequence, weights=None):\n",
    "    if weights is None:\n",
    "        return 1 - np.sum(((np.bincount(sequence)) / len(sequence)) ** 2)\n",
    "    else:\n",
    "        g = 1\n",
    "        for x in np.unique(sequence):\n",
    "            g -= (np.sum( weights[sequence == x]) ** 2)\n",
    "            # print(f\"x: {x} g:{g}\")\n",
    "        return g\n",
    "# def gini(sequence):\n",
    "#     return 1 - np.sum(((np.bincount(sequence)) / len(sequence)) ** 2)\n",
    "\n",
    "\n",
    "def entropy(sequence):\n",
    "    p = (np.bincount(sequence) / len(sequence))\n",
    "    p = p[p > 0]\n",
    "    # print( np.bincount(sequence))\n",
    "    return -np.sum( p * np.log2(p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = class 1,\n",
    "# 2 = class 2\n",
    "data = np.array([1,2,1,1,1,1,2,2,1,1,2])\n",
    "# data = np.array([2,2,2,1.0,1.0,1, 2,2,2,2,2]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini of data is  0.4628099173553719\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini of data is \", gini(data))\n",
    "# print(\"Gini of data is \", gini(data, np.repeat(1/data.shape[0], data.shape[0])))\n",
    "# print(np.repeat(1/data.shape[0], data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of data is  0.9456603046006401\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of data is \", entropy(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "It is a binary classifiation dataset that classify if price is high or not for a cell phone, the label is stored in `price_range` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 21)\n",
      "(300, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>942</td>\n",
       "      <td>1651</td>\n",
       "      <td>1704</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.8</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>1538</td>\n",
       "      <td>2459</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.7</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>1504</td>\n",
       "      <td>1799</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>164</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>873</td>\n",
       "      <td>1394</td>\n",
       "      <td>1944</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1649</td>\n",
       "      <td>1829</td>\n",
       "      <td>2855</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0           1583     1          2.1         1  11       0          14    0.7   \n",
       "1            745     1          0.6         1   5       0          35    0.8   \n",
       "2            832     0          0.7         1   2       1          39    0.7   \n",
       "3           1175     1          1.3         0   2       0          19    0.3   \n",
       "4            695     0          0.5         0  18       1          12    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        148        7  ...        942      1651  1704    17    13          2   \n",
       "1        102        8  ...         89      1538  2459    14     1         16   \n",
       "2        103        4  ...        125      1504  1799     5     2         11   \n",
       "3        164        7  ...        873      1394  1944     9     4          9   \n",
       "4        196        2  ...       1649      1829  2855    16    13          7   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        1             0     1            1  \n",
       "1        1             1     0            0  \n",
       "2        1             0     1            0  \n",
       "3        1             1     0            0  \n",
       "4        1             1     1            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "# print(len(train_df.columns))\n",
    "# print([i for i, _ in enumerate(train_df.columns)])\n",
    "# print(val_df.values[:,:-1].shape)\n",
    "train_df.head()\n",
    "# print(val_df.values[val_df.values[:,-1] ==1].shape)\n",
    "# print(sorted(val_df.values[:,0],  key = lambda a:a))\n",
    "# print( np.asarray(sorted(val_df.values, key=lambda t: t[0])).shape)\n",
    "# print( sorted(val_df.values, key=lambda t: t[0]))\n",
    "# print(val_df.values[:,20].astype(int))\n",
    "# print(val_df.values[:][20].astype(int))\n",
    "# print(np.argmax(np.bincount(val_df.values[:,-1].astype(int))))\n",
    "# print(val_df[\"price_range\"][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the validation data. You should implement two arguments for the Decision Tree algorithm\n",
    "1. **criterion**: The function to measure the quality of a split. Your model should support `gini` for the Gini impurity and `entropy` for the information gain. \n",
    "2. **max_depth**: The maximum depth of the tree. If `max_depth=None`, then nodes are expanded until all leaves are pure. `max_depth=1` equals to split data once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class node():\n",
    "        def __init__(self, fea=None, thre=None, left=None, right=None, clas=None  ):\n",
    "            self.feature = fea\n",
    "            self.thres = thre\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.clas = clas\n",
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None):\n",
    "        self.fea_imp = None\n",
    "        self.criterion = criterion\n",
    "        if criterion == 'gini':\n",
    "            self.measure = gini\n",
    "        elif criterion== 'entropy':\n",
    "            self.measure = entropy\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "        self.alpha = None \n",
    "        self.polarity = None\n",
    "    def get_threshold(self, data, weights=None):\n",
    "        min_impurity = 1e10\n",
    "        th = 0\n",
    "        fea = 0\n",
    "        n, dim = data.shape\n",
    "\n",
    "        for i in range(dim-1):\n",
    "            sorted_fea = np.asarray(sorted(data[:,i], key=lambda a: a))\n",
    "            for j in range(n-1):\n",
    "                tmp_th = (sorted_fea[j] + sorted_fea[j+1]) / 2\n",
    "                # tmp_th = (data[j][i] + data[j+1][i]) / 2\n",
    "                left = (data[data[:,i] < tmp_th])[:,-1].astype(int)\n",
    "                right = (data[data[:,i] >= tmp_th])[:,-1].astype(int)\n",
    "                if weights is None:\n",
    "                    tmp_impu = self.measure(left) * left.shape[0] + self.measure(right) * right.shape[0]\n",
    "                else: \n",
    "                    l_w = weights[data[:,i] < tmp_th]\n",
    "                    l_w /= np.sum(l_w)\n",
    "                    r_w = weights[data[:,i] >= tmp_th]\n",
    "                    r_w /= np.sum(r_w)\n",
    "                    tmp_impu = self.measure(left, l_w) * left.shape[0] + self.measure(right, r_w) * right.shape[0]\n",
    "                if tmp_impu <= min_impurity:\n",
    "                    min_impurity = tmp_impu\n",
    "                    fea = i\n",
    "                    th = tmp_th\n",
    "        # print(f\" {fea} {th} {min_impurity}\")\n",
    "        return fea, th, min_impurity\n",
    "    def build_tree(self, data, depth=None, weights=None):\n",
    "        temp = node()\n",
    "        if  not self.measure(data[:,-1].astype(int)):\n",
    "            temp.clas = int(data[0,-1])\n",
    "        elif depth==0:\n",
    "            temp.clas = (np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "        else:\n",
    "            temp.feature, temp.thres, _ = self.get_threshold(data, weights)\n",
    "            # print(train_df.columns[temp.feature])\n",
    "            self.fea_imp[temp.feature] += 1\n",
    "            left_data = data[data[:, temp.feature] < temp.thres]\n",
    "            right_data = data[data[:, temp.feature]>= temp.thres]\n",
    "            if not len(left_data) or not len(right_data):\n",
    "                temp.clas = (np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "                return temp\n",
    "            if depth is  None:\n",
    "                temp.left = self.build_tree(left_data) \n",
    "                temp.right = self.build_tree(right_data)\n",
    "            elif weights is None:\n",
    "                temp.left = self.build_tree(left_data, depth-1) \n",
    "                temp.right = self.build_tree(right_data, depth-1)\n",
    "            else:\n",
    "                l_w = weights[data[:, temp.feature] < temp.thres]\n",
    "                r_w = weights[data[:, temp.feature]>= temp.thres]\n",
    "                temp.left = self.build_tree(left_data, depth-1, l_w) \n",
    "                temp.right = self.build_tree(right_data, depth-1, r_w)\n",
    "\n",
    "        return temp\n",
    "    def fit(self, x_data, y_data, weights=None):\n",
    "        self.fea_imp = np.zeros(x_data.shape[1]).astype(int)\n",
    "        self.root = self.build_tree(np.hstack((x_data, y_data.reshape(-1,1))), self.max_depth, weights)\n",
    "    def fit_stump(self, x_data, y_data, weights):\n",
    "        min_e = 1e10\n",
    "        po = 1\n",
    "        th = 0\n",
    "        fea = 0\n",
    "        n, dim = x_data.shape\n",
    "\n",
    "        for i in range(dim):\n",
    "            sorted_fea = np.asarray(sorted(x_data[:,i], key=lambda a: a))\n",
    "            for j in range(n-1):\n",
    "                pred = np.zeros((x_data.shape[0])).astype(int)\n",
    "                tmp_po = 1\n",
    "                tmp_th = (sorted_fea[j] + sorted_fea[j+1]) / 2\n",
    "                pred[x_data[:,i] >= tmp_th] = 1\n",
    "                tmp_e = np.sum(weights[pred != y_data])\n",
    "                if tmp_e > 0.5:\n",
    "                    tmp_e = 1 - tmp_e\n",
    "                    tmp_po = -1\n",
    "                if tmp_e < min_e:\n",
    "                        min_e = tmp_e\n",
    "                        fea = i\n",
    "                        th = tmp_th\n",
    "                        po = tmp_po\n",
    "        self.alpha = 0.5 * math.log((1.0 - min_e) / (min_e + 1e-10))\n",
    "        if po == 1:\n",
    "            self.root = node(fea, th, left=node(clas=0), right=node(clas=1))\n",
    "        else:\n",
    "            self.polarity = -1\n",
    "            self.root = node(fea, th, left=node(clas=1), right=node(clas=0))\n",
    "    def predict(self, x_data, y_data=None, weights=None):\n",
    "        pred = np.zeros((x_data.shape[0])).astype(int)\n",
    "        c = 0\n",
    "        e = 0\n",
    "        for i in range(x_data.shape[0]):\n",
    "            cur_node = self.root\n",
    "            while cur_node.clas is None:\n",
    "                if x_data[i][cur_node.feature] < cur_node.thres:\n",
    "                    cur_node = cur_node.left\n",
    "                else:\n",
    "                    cur_node = cur_node.right\n",
    "            pred[i] = cur_node.clas\n",
    "            # if self.polarity is not None:\n",
    "                # pred[i] = int(not pred[i]) \n",
    "        if y_data is not None:\n",
    "            c = np.sum(pred == y_data) / x_data.shape[0]\n",
    "            if weights is not None:\n",
    "                e = np.sum(weights[pred != y_data])\n",
    "            return pred, c, e\n",
    "        else:\n",
    "            return pred\n",
    "    def print_acc(self, acc):\n",
    "        print(f'criterion = {self.criterion}')\n",
    "        print(f'max depth = {self.max_depth}')\n",
    "        print(f'acc       = {acc}')\n",
    "        print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Using `criterion=gini`, showing the accuracy score of validation data by `max_depth=3` and `max_depth=10`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini\n",
      "max depth = 3\n",
      "acc       = 0.92\n",
      "====================\n",
      "criterion = gini\n",
      "max depth = 10\n",
      "acc       = 0.94\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_depth3.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_depth3.print_acc(clf_depth3.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])\n",
    "clf_depth10 = DecisionTree(criterion='gini', max_depth=10)\n",
    "clf_depth10.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_depth10.print_acc(clf_depth10.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])\n",
    "# print((clf_depth10.fea_imp))\n",
    "# print(len(clf_depth10.fea_imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Using `max_depth=3`, showing the accuracy score of validation data by `criterion=gini` and `criterion=entropy`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini\n",
      "max depth = 3\n",
      "acc       = 0.92\n",
      "====================\n",
      "criterion = entropy\n",
      "max depth = 3\n",
      "acc       = 0.9333333333333333\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_gini.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_gini.print_acc(clf_gini.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])\n",
    "clf_entropy = DecisionTree(criterion='entropy', max_depth=3)\n",
    "clf_entropy.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_entropy.print_acc(clf_entropy.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Your decisition tree scores should over **0.9**. It may suffer from overfitting, if so, you can tune the hyperparameter such as `max_depth`\n",
    "- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n",
    "- Hint: You can use the recursive method to build the nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n",
    "\n",
    "- You can simply plot the **counts of feature used** for building tree without normalize the importance. Take the figure below as example, outlook feature has been used for splitting for almost 50 times. Therefore, it has the largest importance\n",
    "\n",
    "![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.barh( train_df.columns[:-1], (clf_depth10.fea_imp))\n",
    "plt.ylabel('feature names')\n",
    "plt.xlabel('feature importance')\n",
    "plt.xticks(np.arange(max(clf_depth10.fea_imp)+1))\n",
    "plt.yticks(np.array(range(len(clf_depth10.fea_imp) )))\n",
    "plt.gca().grid(axis='x', which='major')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('fi.png', dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "implement the AdaBooest algorithm by using the CART you just implemented from question 2 as base learner. You should implement one arguments for the AdaBooest.\n",
    "1. **n_estimators**: The maximum number of estimators at which boosting is terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators):\n",
    "        self.clf_n = n_estimators\n",
    "        self.clfs = []\n",
    "        self.clf_w = []\n",
    "    def fit(self, x_data, y_data):\n",
    "        sample_w = np.ones(x_data.shape[0])\n",
    "        for i in range(self.clf_n):\n",
    "            # print(\"Run No. of Iteration: %d\" % (i+1))\n",
    "            sample_w /= np.sum(sample_w)\n",
    "            clf = DecisionTree(criterion='gini', max_depth=1)\n",
    "            clf.fit_stump(x_data, y_data, sample_w)\n",
    "            pred, acc, error = clf.predict(x_data, y_data, weights =sample_w)\n",
    "            # if error > 0.5:\n",
    "                # clf.polarity = -1\n",
    "            # print(f\"acc: {acc} error: {error} cls_w: {clf.alpha}\")\n",
    "            for i in range(sample_w.shape[0]):\n",
    "                if pred[i] == y_data[i]:\n",
    "                    sample_w[i] *= (math.e ** -clf.alpha)\n",
    "                else:\n",
    "                    sample_w[i] *= (math.e ** clf.alpha)\n",
    "\n",
    "            self.clfs.append(clf)\n",
    "    def predict(self, x_data, y_data=None):\n",
    "        pred = np.zeros(x_data.shape[0])\n",
    "        c = 0\n",
    "        for clf in self.clfs:\n",
    "            p = clf.predict(x_data)\n",
    "            p[p == 0] = -1\n",
    "            pred += clf.alpha * p\n",
    "        pred[pred <= 0] = 0\n",
    "        pred[pred > 0] = 1\n",
    "\n",
    "        if y_data is not None:\n",
    "            c = np.sum(pred == y_data) / x_data.shape[0]\n",
    "            return pred, c\n",
    "        else:\n",
    "            return pred\n",
    "    def print_acc(self, acc):\n",
    "        print(f'number of estimators = {self.clf_n}')\n",
    "        print(f'acc       = {acc}')\n",
    "        print('====================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "print(clf.score(val_df.values[:,:-1], val_df.values[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Show the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimators = 10\n",
      "acc       = 0.94\n",
      "====================\n",
      "number of estimators = 100\n",
      "acc       = 0.9733333333333334\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "Ada_10 = AdaBoost(n_estimators=10)\n",
    "Ada_10.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "Ada_10.print_acc((Ada_10.predict(val_df.values[:,:-1], val_df.values[:,-1]))[1])\n",
    "Ada_100 = AdaBoost(n_estimators=100)\n",
    "Ada_100.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "Ada_100.print_acc((Ada_100.predict(val_df.values[:,:-1], val_df.values[:,-1]))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement three arguments for the Random Forest.\n",
    "\n",
    "1. **n_estimators**: The number of trees in the forest. \n",
    "2. **max_features**: The number of random select features to consider when looking for the best split\n",
    "3. **bootstrap**: Whether bootstrap samples are used when building tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "class RandomForest():\n",
    "    def __init__(self, n_estimators, max_features, boostrap=True, criterion='gini', max_depth=None):\n",
    "        self.clf_n = n_estimators\n",
    "        self.max_features = int(np.round(max_features))\n",
    "        self.boostrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.clfs = []\n",
    "        self.fea_ids = []\n",
    "        for i in range(self.clf_n):\n",
    "            self.clfs.append(DecisionTree(self.criterion, self.max_depth))\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        for clf in self.clfs:\n",
    "            fea_id = rd.sample(range(x_data.shape[1]), self.max_features)\n",
    "            self.fea_ids.append(fea_id)\n",
    "            if self.boostrap:\n",
    "                # sample_id = rd.sample(range(x_data.shape[0]), k=int(x_data.shape[0]*2/3))\n",
    "                sample_id = rd.choices(range(x_data.shape[0]), k=int(x_data.shape[0]*2/3))\n",
    "                clf.fit(x_data[sample_id][:,fea_id], y_data[sample_id])\n",
    "            else:\n",
    "                clf.fit(x_data[:,fea_id], y_data)\n",
    "    def predict(self, x_data, y_data=None):\n",
    "        pred = np.zeros(x_data.shape[0])\n",
    "        for i in range(self.clf_n):\n",
    "            # print(x.predict(x_data)[0])\n",
    "            pred += self.clfs[i].predict(x_data[:,self.fea_ids[i]])\n",
    "        # print(pred)\n",
    "        pred[pred <= int(self.clf_n/2)] = 0\n",
    "        pred[pred > int(self.clf_n/2)] = 1\n",
    "        # print(pred)\n",
    "        \n",
    "        if y_data is not None:\n",
    "            c = np.sum(pred == y_data) / x_data.shape[0]\n",
    "            return pred, c\n",
    "        else:\n",
    "            return pred\n",
    "    def print_acc(self, acc):\n",
    "        print(f'n estimators = {self.clf_n}')\n",
    "        print(f'max features = {self.max_features}')\n",
    "        print(f'boostrap     = {self.boostrap}')\n",
    "        print(f'criterion    = {self.criterion}')\n",
    "        print(f'max depth    = {self.max_depth}')\n",
    "        print(f'acc          = {acc}')\n",
    "        print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1\n",
    "Using `criterion=gini`, `max_depth=None`, `max_features=sqrt(n_features)`, showing the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n estimators = 10\n",
      "max features = 5\n",
      "boostrap     = True\n",
      "criterion    = gini\n",
      "max depth    = None\n",
      "acc          = 0.7133333333333334\n",
      "====================\n",
      "n estimators = 100\n",
      "max features = 5\n",
      "boostrap     = True\n",
      "criterion    = gini\n",
      "max depth    = None\n",
      "acc          = 0.9066666666666666\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(train_df.values.shape[1]))\n",
    "clf_10tree.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_10tree.print_acc(clf_10tree.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])\n",
    "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(train_df.values.shape[1]))\n",
    "clf_100tree.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_100tree.print_acc(clf_100tree.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2\n",
    "Using `criterion=gini`, `max_depth=None`, `n_estimators=10`, showing the accuracy score of validation data by `max_features=sqrt(n_features)` and `max_features=n_features`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n estimators = 10\n",
      "max features = 5\n",
      "boostrap     = True\n",
      "criterion    = gini\n",
      "max depth    = None\n",
      "acc          = 0.81\n",
      "====================\n",
      "n estimators = 10\n",
      "max features = 20\n",
      "boostrap     = True\n",
      "criterion    = gini\n",
      "max depth    = None\n",
      "acc          = 0.9466666666666667\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "clf_random_features = RandomForest(n_estimators=10, max_features=np.sqrt(train_df.values.shape[1]))\n",
    "clf_random_features.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_random_features.print_acc(clf_random_features.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])\n",
    "clf_all_features = RandomForest(n_estimators=10, max_features=train_df.values.shape[1]-1)\n",
    "clf_all_features.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_all_features.print_acc(clf_all_features.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n estimators = 200\n",
      "max features = 20\n",
      "boostrap     = True\n",
      "criterion    = gini\n",
      "max depth    = None\n",
      "acc          = 0.9666666666666667\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "clf_all_features = RandomForest(n_estimators=200, max_features=train_df.values.shape[1]-1)\n",
    "clf_all_features.fit(train_df.values[:,:-1], train_df.values[:,-1])\n",
    "clf_all_features.print_acc(clf_all_features.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Train and tune your model on a real-world dataset\n",
    "Try you best to get higher accuracy score of your model. After parameter tuning, you can train your model on the full dataset (train + val).\n",
    "- Feature engineering\n",
    "- Hyperparameter tuning\n",
    "- Implement any other ensemble methods, such as gradient boosting. Please note that you **can not** call any package. Also, only ensemble method can be used. Neural network method is not allowed to used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_your_model(data):\n",
    "    m = AdaBoost(n_estimators=150)\n",
    "    m.fit(data[:,:-1], data[:,-1])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = train_your_model(np.vstack((train_df.values, val_df.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimators = 150\n",
      "acc       = 1.0\n",
      "====================\n",
      "number of estimators = 150\n",
      "acc       = 1.0\n",
      "====================\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x_test = pd.read_csv('x_test.csv').values\n",
    "my_model.print_acc(my_model.predict(val_df.values[:,:-1], val_df.values[:,-1])[1])\n",
    "my_model.print_acc(my_model.predict(train_df.values[:,:-1], train_df.values[:,-1])[1])\n",
    "y_pred = my_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary\n",
    "If you have trouble to implement this homework, TA strongly recommend watching [this video](https://www.youtube.com/watch?v=LDRbO9a6XPU), which explains Decision Tree model clearly. But don't copy code from any resources, try to finish this homework by yourself! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT MODIFY CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [348], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 3\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_range\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest-set accuarcy score: \u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1730\u001b[0m     f,\n\u001b[1;32m   1731\u001b[0m     mode,\n\u001b[1;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1738\u001b[0m )\n\u001b[1;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    858\u001b[0m             handle,\n\u001b[1;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    863\u001b[0m         )\n\u001b[1;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y_test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('y_test.csv')['price_range'].values\n",
    "\n",
    "print('Test-set accuarcy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** We will check your result for Question 3 manually *** (5 points)\n",
      "*** We will check your result for Question 6 manually *** (20 points)\n",
      "Approximate score range: 45.0 ~ 70.0\n",
      "*** This score is only for reference ***\n"
     ]
    }
   ],
   "source": [
    "def discrete_checker(score, thres, clf, name, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "        return score\n",
    "    else:\n",
    "        print(f\"{name} failed\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def patient_checker(score, thres, CLS, kwargs, name,\n",
    "                    x_train, y_train, x_test, y_test, patient=10):\n",
    "    while patient > 0:\n",
    "        patient -= 1\n",
    "        clf = CLS(**kwargs)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "            return score\n",
    "        # else:\n",
    "        #     print(f\"{name} \")\n",
    "        #     print(accuracy_score(y_test, y_pred)) \n",
    "    print(f\"{name} failed\")\n",
    "    print(\"Considering the randomness, we will check it manually\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
    "    df = pd.read_csv(\n",
    "        file_url,\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )\n",
    "\n",
    "    df['Target'] = (df[\"Age\"] > 15).astype(int)\n",
    "    df = df.drop(labels=[\"Age\"], axis=\"columns\")\n",
    "\n",
    "    train_idx = range(0, len(df), 10)\n",
    "    test_idx = range(1, len(df), 20)\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "    x_train = train_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    feature_names = x_train.columns.values\n",
    "    x_train = x_train.values\n",
    "    y_train = train_df['Target'].values\n",
    "\n",
    "    x_test = test_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    x_test = x_test.values\n",
    "    y_test = test_df['Target'].values\n",
    "    return x_train, y_train, x_test, y_test, feature_names\n",
    "\n",
    "\n",
    "score = 0\n",
    "\n",
    "data = np.array([1, 2])\n",
    "if abs(gini(data) - 0.5) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"gini test failed\")\n",
    "\n",
    "if abs(entropy(data) - 1) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"entropy test failed\")\n",
    "\n",
    "x_train, y_train, x_test, y_test, feature_names = load_dataset()\n",
    "\n",
    "score += discrete_checker(5, 0.9337,\n",
    "                          DecisionTree(criterion='gini', max_depth=3),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9036,\n",
    "                          DecisionTree(criterion='gini', max_depth=10),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=10)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9096,\n",
    "                          DecisionTree(criterion='entropy', max_depth=3),\n",
    "                          \"DecisionTree(criterion='entropy', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "print(\"*** We will check your result for Question 3 manually *** (5 points)\")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.91, AdaBoost, {\"n_estimators\": 10},\n",
    "    \"AdaBoost(n_estimators=10)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.87, AdaBoost, {\"n_estimators\": 100},\n",
    "    \"AdaBoost(n_estimators=100)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=10, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 100, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=100, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.92, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": x_train.shape[1]},\n",
    "    \"RandomForest(n_estimators=10, max_features=n_features)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "print(\"*** We will check your result for Question 6 manually *** (20 points)\")\n",
    "print(\"Approximate score range:\", score, \"~\", score + 25)\n",
    "print(\"*** This score is only for reference ***\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
